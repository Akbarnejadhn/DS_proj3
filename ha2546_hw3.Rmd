---
title: "Methods of Classification"
author: "Hana Akbarnejad"
date: "4/10/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(viridis)
library(ggplot2)
library(readr)
library(patchwork)

library(caret)
library(glmnet)
library(MASS)
library(e1071)
library(pROC)
library(AppliedPredictiveModeling)
library(ISLR)



knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
theme_set(theme_minimal() + theme(legend.position = "bottom"))
```


\newpage

```{r data, include=FALSE}

data(Weekly)
weekly_data = Weekly
head(weekly_data)

weekly_data = weekly_data %>%
  janitor::clean_names() %>% 
  dplyr::select(direction, everything(), -today) %>%   # not including year (?)
  mutate(direction = as.factor(direction))
```

### (a) Produce some graphical summaries of the Weekly data

Add some data description + binary outcome (direction)

```{r eda, echo=FALSE}

theme1 <- transparentTheme(trans = .4)
theme1$strip.background$col <- rgb(.0, .6, .2, .2)
trellis.par.set(theme1)
featurePlot(x = weekly_data[, 2:8],
y = weekly_data$direction,
scales = list(x=list(relation="free"),
y=list(relation="free")),
plot = "density", pch = "|",
auto.key = list(columns = 2))
```

Add some description of data

### (b) Use the full data set to perform a logistic regression with Direction as the response and the five Lag variables plus Volume as predictors. Do any of the predictors appear to be statistically significant? If so, which ones?

```{r logistic_reg}

ctrl = trainControl(method = "repeatedcv",
                    repeats = 5,
                    summaryFunction = twoClassSummary,
                    classProbs = TRUE)

set.seed(2020)

glm_fit = train(x = weekly_data[,3:8],   # using lag variables and volume as predictors
                y = weekly_data$direction,
                method = "glm",
                metric = "ROC",
                trControl = ctrl)

summary(glm_fit)
```

lag1 and lag2 are significant

### (c) Compute the confusion matrix and overall fraction of correct predictions. Briefly explain what the confusion matrix is telling you.

```{r confusion_matrix}

contrasts(weekly_data$direction) # to know what is 0 and what is 1>>> 0:down, 1:up

# partitioning data into train and test
train_rows = createDataPartition(y = weekly_data$direction,
                    p = 2/3,
                    list = FALSE)
train_data = weekly_data[train_rows,]
test_data = weekly_data[-train_rows,]

glm_fit_train = glm(direction ~ lag1+lag2+lag3+lag4+lag5+volume,
                   data = weekly_data,
                   subset = train_rows,
                   family = binomial)

test_pred_prob = predict(glm_fit_train, newdata = test_data,
                    type = "response")

test_pred = rep("Down", length(test_pred_prob))
test_pred[test_pred_prob>0.5] = "Up"

confusionMatrix(data = as.factor(test_pred),
                reference = weekly_data$direction[-train_rows],
                positive = "Up")
```

Add explanations of confusion matrix

### (d) Plot the ROC curve using the predicted probability from logistic regression and report the AUC.
```{r roc_curve}

roc_glm = roc(weekly_data$direction[-train_rows], test_pred_prob)
plot(roc_glm, legacy.axes = TRUE, print.auc = TRUE)
plot(smooth(roc_glm), col = 4, add = TRUE)

roc_glm$auc
```

talk a little about ROC curve here...

### (e) Now fit the logistic regression model using a training data period from 1990 to 2008, with Lag1 and Lag2 as the predictors. Plot the ROC curve using the held out data (that is, the data from 2009 and 2010) and report the AUC.
```{r}

train_year_data = weekly_data %>% 
  filter(year %in% (1990:2008))

test_year_data = weekly_data %>% 
  filter(year %in% 2009:2010)

glm_fit_train2 = glm(direction ~ lag1+lag2,
                   data = train_year_data,
                   family = binomial)

test_pred_prob2 = predict(glm_fit_train2, newdata = test_year_data,
                    type = "response")

test_pred2 = rep("Down", length(test_pred_prob2))
test_pred2[test_pred_prob2>0.5] = "Up"

roc_glm2 = roc(test_year_data$direction, test_pred_prob2)
plot(roc_glm2, legacy.axes = TRUE, print.auc = TRUE)
plot(smooth(roc_glm2), col = 4, add = TRUE)

roc_glm2$auc

#glm caret
set.seed(2020)

model_glm = train(x = train_year_data[,3:4],
                  y = train_year_data$direction,
                  method = "glm",
                  metric = "ROC",
                  trControl = ctrl)
```

Add some explainations...

### Repeat (f) using LDA and QDA

**LDA**
```{r lda}

lda_fit = lda(direction~ lag1+lag2,
              data = train_year_data)
plot(lda_fit)

lda_pred = predict(lda_fit, newdata = test_year_data)
roc_lda = roc(test_year_data$direction, lda_pred$posterior[,2],
              levels = c("Down", "Up"))

plot(roc_lda, legacy.axes = TRUE, print.auc = TRUE)
plot(smooth(roc_lda), col = 4, add = TRUE)

#LDA caret
set.seed(2020)

model_lda = train(x = train_year_data[,3:4],
                y = train_year_data$direction,
                method = "lda",
                metric = "ROC",
                trControl = ctrl)
```


**QDA**
```{r qda}

qda_fit = qda(direction~ lag1+lag2,
              data = train_year_data)

qda_pred = predict(qda_fit, newdata = test_year_data)
roc_qda = roc(test_year_data$direction, qda_pred$posterior[,2],
              levels = c("Down", "Up"))

plot(roc_qda, legacy.axes = TRUE, print.auc = TRUE)
plot(smooth(roc_qda), col = 4, add = TRUE)


#QDA caret
set.seed(2020)

model_qda = train(x = train_year_data[,3:4],
                  y = train_year_data$direction,
                  method = "qda",
                  metric = "ROC",
                  trControl = ctrl)
```

### Repeat (e) using KNN.
```{r knn}

#KNN caret
set.seed(2020)

model_knn = train(x = train_year_data[,3:4],
                  y = train_year_data$direction,
                  method = "knn",
                  preProcess = c("center","scale"),
                  tuneGrid = data.frame(k = seq(1,300,by=5)),
                  trControl = ctrl)
ggplot(model_knn) # why does it look like this
```

### Model comparison
```{r}

res = resamples(list(GLM = model_glm,
                LDA = model_lda,
                QDA = model_qda,
                KNN = model_knn))
summary(res)
```

```{r}

glm.pred = predict(model_glm, newdata = test_year_data, type = "prob")[,2]
lda.pred = predict(model_lda, newdata = test_year_data, type = "prob")[,2]
qda.pred = predict(model_qda, newdata = test_year_data, type = "prob")[,2]
knn.pred = predict(model_knn, newdata = test_year_data, type = "prob")[,2]


roc.glm = roc(test_year_data$direction, glm.pred)
roc.lda = roc(test_year_data$direction, lda.pred)
roc.qda = roc(test_year_data$direction, qda.pred)
roc.knn = roc(test_year_data$direction, knn.pred)


auc = c(roc.glm$auc[1], roc.lda$auc[1],
        roc.qda$auc[1], roc.knn$auc[1])

plot(roc.glm, legacy.axes = TRUE)
plot(roc.lda, col = 3, add = TRUE)
plot(roc.qda, col = 4, add = TRUE)
plot(roc.knn, col = 6, add = TRUE)

modelNames = c("glm","lda","qda","knn")
legend("bottomright", legend = paste0(modelNames, ": ", round(auc,3)),
       col = 1:6, lwd = 2)
```

Add explanation...